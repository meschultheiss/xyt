{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94a42b8-6ab2-4117-bb2f-d773a16d19a8",
   "metadata": {},
   "source": [
    "## Instance: GPStoActionspace()\n",
    "### Input\n",
    "Takes as input the output of `GPSAnalytics().metrics.get_metrics()` -> act (dataframe)\n",
    "\n",
    "### Introduction\n",
    "This notebook applies centrography to the MOBIS data at state 2, focusing on activity-level aggregation.\n",
    "\n",
    "The objective is to generate key metrics characterizing the activity space for a more in-depth exploration of spatial familiarity.\n",
    "\n",
    "Spatial familiarity metrics encompass a composite evaluation of location history, daily activity-space variability, and spatial innovation. Achieving this involves intricate data transformations utilizing advanced point-pattern centrography. Leveraging a dataset with labeled locations, including purpose and visit counts, over a specific time frame, marked point pattern analysis (PPA) facilitates the study of individual action spaces (Baddeley, Rubak, and Turner 2015).\n",
    "\n",
    "The implementation of centrography (utilizing the Python Spatial Analysis library) extracts characteristics to describe the activity space:\n",
    "\n",
    "- **Points**: Marked visited places with counts of visits, purpose labels (home, work, leisure, duties), unique location IDs, and intensity (average number of event points per unit of the convex hull area).\n",
    "- **Centers**: The mean center and weighted mean centers (weighted by the count of visits).\n",
    "- **Distances**: Standard distance, offering a one-dimensional measure of how dispersed visited locations are around their mean center, and the sum of distances from home.\n",
    "- **Shapes**: Standard deviational ellipse, providing a two-dimensional measure of the dispersion of visited locations, and the minimum convex hull of frequently visited places.\n",
    "\n",
    "This approach predominantly relies on the Python library for spatial analysis, PySAL.\n",
    "\n",
    "### Public methods\n",
    "The public methods should be the following:\n",
    "- `GSPtoActionspace().compute_action_space(act, aggreg_method = 'user_id'/'user_id_day',plot_ellipses = False)` -> AS (dataframe) Get from Part 0 and 1 and 2 below\n",
    "- `GSPtoActionspace().covariance_matric(AS)` Get from Part 3 below\n",
    "- `GSPtoActionspace().plot_action_space(act, AS, user_subset = ['CH15029', 'CH16871'], how = 'vignette'/'folium', save = False)` Get from Part 4 below\n",
    "- `GPStoActionspace().inno_rate(mtf_, AS_day, user_id_, phase=None, treatment=None)` Get from Part 5 below\n",
    "\n",
    "### Methodology\n",
    "\n",
    "$$\n",
    "\\text{(Eq. 3) } \\quad\n",
    "Regularity = \\dfrac{n_f + 1}{n} \\text{; with $n_f$ the number of frequently visited locations and $n$ the total number of locations} \n",
    "\\\\ \\text{(Eq. 4) }  \\quad\n",
    "    Frequency=\n",
    "    \\begin{cases}\n",
    "      \\text{'most visited'}, & \\text{for}\\ \\arg\\max({f_i}) \\\\\n",
    "      \\text{'frequent visits'}, & \\text{for}\\ f_i > 0.5 \\cdot \\arg\\max({f_i}) \\\\\n",
    "      \\text{'occasional visits'}, & \\text{for}\\ f_i \\leq 0.5 \\cdot \\arg\\max({f_i}) \\\\\n",
    "      \\text{'visited once'}, & \\text{if}\\ f_i = 1\n",
    "    \\end{cases} \n",
    "    \\text{with $f_i$ the count of visits at location $i$}\n",
    "\\\\ \\text{(Eq. 5) }  \\quad\n",
    "    Proximity =\n",
    "    \\dfrac{SD_{freq}}{SD_{all}} \\text{ is }\n",
    "        \\begin{cases}\n",
    "          > 1 \\text{ for dispersed habitual activity space and close innovative activity space} \\\\\n",
    "          \\approx 1 \\text{ for homogeneous activity spaces} \\\\\n",
    "          < 1 \\text{ for dispersed innovative activity space and close habitual activity space }\n",
    "        \\end{cases} \n",
    "\\\\\n",
    "\\qquad  \\text{Given the coordinates $(x,y)$ of $i$ locations :}\n",
    "\\\\\n",
    "\\qquad  \\text{(5.1) } \\text{with}  \\quad\n",
    "SD_{freq} = \\displaystyle \\sqrt{\\frac{\\sum^n_{i=1}(x_i-x_{home})^2}{n} + \\frac{\\sum^n_{i=1}(y_i-y_{home})^2}{n}}\n",
    "\\text{  } \\forall \\text{nodes } n_i(x_i,y_i)\\in C_f = \\{\\text{'frequently visited places', 'most visited place'}\\}\n",
    "\\\\ \\qquad \\text{(5.2) } \\text{and}  \\quad\n",
    "SD_{all} = \\displaystyle \\sqrt{\\frac{\\sum^n_{i=1}(x_i-x_{home})^2}{n} + \\frac{\\sum^n_{i=1}(y_i-y_{home})^2}{n}}\n",
    "\\text{  } \\forall \\text{nodes } n_i(x_i,y_i) \\in C =\\{\\text{'all visited places}\\}\n",
    "\\\\ \\text{(Eq. 6) }  \\quad\n",
    "    \\textit{Home shift} = \n",
    "    \\sqrt {\\left( {x_{home} - x_{wmc} } \\right)^2 + \\left( {y_{home} - y_{wmc} } \\right)^2 }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a07ef-3a08-42fd-a517-49624ee2dcc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:32.357087Z",
     "start_time": "2023-11-21T15:30:32.048199Z"
    }
   },
   "outputs": [],
   "source": [
    "from xyt import GPSAnalytics, GPStoActionspace, GPStoGraph\n",
    "\n",
    "from functions_preprocessing import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "action_space = GPStoActionspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91679489-e6c9-4dc6-a0df-5a9d67f586ba",
   "metadata": {},
   "source": [
    "### Part 0\n",
    "Preprocess the input so rest of the finctions work\n",
    "maybe better to add this line directly in the GPSAnalytics().get_metrics method ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172c088-4026-4fee-b251-0472a317c44b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:34.116262Z",
     "start_time": "2023-11-21T15:30:32.358204Z"
    }
   },
   "outputs": [],
   "source": [
    "act = pd.read_pickle('sample_data/staypoint_sample_panel.pkl').reset_index()\n",
    "act.rename(columns={'IDNO':'user_id', 'id':'activity_id'}, inplace=True)\n",
    "# Extract longitude and latitude into separate columns\n",
    "act['lon'] = act['geometry'].apply(lambda point: point.x)\n",
    "act['lat'] = act['geometry'].apply(lambda point: point.y)\n",
    "#Parse the activity df to datetime and geopandas\n",
    "act = parse_time_geo_data(act, geo_columns=['lon','lat'], datetime_format='%Y-%m-%d %H:%M:%S', CRS2='EPSG:2056')\n",
    "del act['geometry']\n",
    "\n",
    "leg = pd.read_pickle('sample_data/leg_sample_panel.pkl').reset_index()\n",
    "leg.rename(columns={'id':'leg_id', 'IDNO':'user_id'}, inplace=True)\n",
    "leg['started_at'] = pd.to_datetime(leg['started_at'])\n",
    "leg['finished_at'] = pd.to_datetime(leg['finished_at'])\n",
    "\n",
    "# Add the leg destination activity_id\n",
    "leg = find_next_activity_id(leg, act)\n",
    "\n",
    "# Add a 'length' column in meters\n",
    "leg = gpd.GeoDataFrame(leg, geometry='geometry', crs='EPSG:4327')\n",
    "leg['length'] = leg.to_crs(crs='EPSG:2056').length\n",
    "\n",
    "# Calculate the duration in seconds and add a 'duration' column in minutes\n",
    "leg['duration'] = (leg['finished_at'] - leg['started_at']).dt.total_seconds() / 60\n",
    "\n",
    "metrics = GPSAnalytics()\n",
    "\n",
    "staypoint1 = metrics.split_overnight(act)\n",
    "staypoint2 = metrics.spatial_clustering(staypoint1)\n",
    "act_orig = act.copy()\n",
    "act = metrics.get_metrics(staypoint2, leg)\n",
    "\n",
    "act.cluster_size = act.cluster_size.astype(int) #make sure we have the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37e2d7-72b9-4a8f-b728-f8e959f65727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:34.196774Z",
     "start_time": "2023-11-21T15:30:34.118004Z"
    }
   },
   "outputs": [],
   "source": [
    "#I need to get the MAIN home location ID first, as in the data above one user_id may have different home location for each day.\n",
    "\n",
    "# Group by 'user_id' and the date part of 'started_at'\n",
    "grouped = act.groupby(['user_id', act['started_at'].dt.date])\n",
    "\n",
    "# Find the most recurrent 'home_location_id' for each user and day\n",
    "most_recurrent_home = grouped['home_location_id'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "# Most recurrent home_id per user\n",
    "most_recurrent_home_id = most_recurrent_home.value_counts().idxmax()\n",
    "\n",
    "# Create a mapping of user_id and date to the most recurrent home_location_id\n",
    "mapping = most_recurrent_home.reset_index().set_index(['user_id','started_at']).to_dict()['home_location_id']\n",
    "\n",
    "# Map the values to the original DataFrame to create the new column\n",
    "act['main_home_location_id'] = act.set_index(['user_id', act['started_at'].dt.date]).index.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf16fc0-74f4-44e3-8046-c856e22f8e73",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Process the action space metrics per user_id (all days, one_user) or per user_id_day (one day, one user)\n",
    "- `GSPtoActionspace().compute_action_space(act, aggreg_method = 'user_id'/'user_id_day',plot_ellipses = False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec13b8f-a034-4b9a-8a05-6caa2a0fdca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:35.371093Z",
     "start_time": "2023-11-21T15:30:34.198062Z"
    }
   },
   "outputs": [],
   "source": [
    "#aggregation_method = 'user_id_day'  # Change this to 'user_id' or 'user_id_day'\n",
    "aggregation_method = 'user_id'  # Change this to 'user_id' or 'user_id_day'\n",
    "act_spc = action_space.compute_action_space(act, aggregation_method=aggregation_method)\n",
    "mymap = action_space.plot_ellipses(act_spc, aggregation_method=aggregation_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb5155a5273e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:35.592523Z",
     "start_time": "2023-11-21T15:30:35.371476Z"
    }
   },
   "outputs": [],
   "source": [
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2156571-0bc0-4a11-bdf6-8ba0e932a446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:35.631284Z",
     "start_time": "2023-11-21T15:30:35.576408Z"
    }
   },
   "outputs": [],
   "source": [
    "act_spc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968d4b9-5ebc-42bf-8375-0c745ab57f04",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Plot the ellipses, get one color per user and user_id on hover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1c02f-684d-4495-a6d3-f83857ae0ea2",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Covariance matrix of the Action Space Args we computed\n",
    "- `GSPtoActionspace().covariance_matric(AS)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d880edd-0c7a-4a00-95ef-7d7e475770f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:36.073504Z",
     "start_time": "2023-11-21T15:30:35.630132Z"
    }
   },
   "outputs": [],
   "source": [
    "action_space.covariance_matrix(action_space=act_spc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339c28b-6bf0-4b28-bf1f-20ba191f23e7",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "More plots, including the points from `act` and ellipse from `AS`\n",
    "- `GSPtoActionspace().plot_action_space(act, AS, user_subset = ['CH15029', 'CH16871'], how = 'vignette'/'folium', save = False)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_spc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61561b-e37a-4857-9c0b-42916f5e848e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T15:30:36.075757Z",
     "start_time": "2023-11-21T15:30:35.876805Z"
    }
   },
   "outputs": [],
   "source": [
    "#action_space.plot_action_space(act, act_spc, user=\"CH16871_20230605\", how=\"vignette\", save=False)\n",
    "action_space.plot_action_space(act, act_spc, user=\"CH16871\", how=\"vignette\", save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f17375-b989-471b-ab65-d7b6973877cb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T15:30:35.962103Z"
    }
   },
   "outputs": [],
   "source": [
    "#action_space.plot_action_space(act, act_spc, user=\"CH16871_20230605\", how=\"folium\", save=False)\n",
    "action_space.plot_action_space(act, act_spc, user=\"CH16871\", how=\"folium\", save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be2366-28d5-4987-bad9-d5a01cdf9b66",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "**Method**\n",
    "- `GPStoActionspace().inno_rate(mtf_, AS_day, user_id_, phase=None, treatment=None)`\n",
    "\n",
    "**Objective**\n",
    "\n",
    "The objective here is to plot the innovation rate\n",
    "\n",
    "**The necessary data for this method are :**\n",
    "- `GPStoGraph().get_graphs()` -> mtf_ \n",
    "- `GSPtoActionspace().compute_action_space(act, aggreg_method = 'user_id_day')` -> AS_day\n",
    "\n",
    "**phase and treatment**\n",
    "\n",
    "GPS data often come with a treatment e.g. {control, treat_1, treat_2} or phase column e.g. {before, after}. Here it is not the case, so no hue is necessary on the plots. But please keep the option of plotting hue for different treatment or phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_spc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f84696-5a6c-4ad3-9ecc-b32663a0a06e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T15:30:35.964479Z"
    }
   },
   "outputs": [],
   "source": [
    "leg = pd.read_pickle('sample_data/leg_sample_panel.pkl').reset_index()\n",
    "leg.rename(columns={'id':'leg_id', 'IDNO':'user_id'}, inplace=True)\n",
    "leg['started_at'] = pd.to_datetime(leg['started_at'])\n",
    "leg['finished_at'] = pd.to_datetime(leg['finished_at'])\n",
    "\n",
    "# Add the leg destination activity_id\n",
    "leg = find_next_activity_id(leg, act)\n",
    "\n",
    "# Add a 'length' column in meters\n",
    "leg = gpd.GeoDataFrame(leg, geometry='geometry', crs='EPSG:4327')\n",
    "leg['length'] = leg.to_crs(crs='EPSG:2056').length\n",
    "\n",
    "# Calculate the duration in seconds and add a 'duration' column in minutes\n",
    "leg['duration'] = (leg['finished_at'] - leg['started_at']).dt.total_seconds() / 60\n",
    "\n",
    "\n",
    "metrics = GPSAnalytics()\n",
    "\n",
    "staypoint1 = metrics.split_overnight(act_orig)\n",
    "staypoint2 = metrics.spatial_clustering(staypoint1)\n",
    "extended_staypoint = metrics.get_metrics(staypoint2, leg)\n",
    "day_staypoint = metrics.get_daily_metrics(extended_staypoint)\n",
    "\n",
    "graphs = GPStoGraph()\n",
    "multiday_graph = graphs.get_graphs(extended_staypoint)\n",
    "\n",
    "action_space.get_inno_rate_per_phase(act_spc, multiday_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78777eb8-3e1b-49b3-8516-e60fa0100e95",
   "metadata": {},
   "source": [
    "\n",
    "the script below is implemented in case of phase and treatment. In the sample data I have no phase and no treatment, but I still want to be able to plot the innovation rate. Sorry it is messy. It you cannot adapt I will do it myself later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff646114-2943-47d6-8c7d-2e8fca527af5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T15:30:35.970272Z"
    }
   },
   "outputs": [],
   "source": [
    "to_plot = 800\n",
    "#Init df to be populated with the innovation rates per cluster\n",
    "df_innov_rate_1 = pd.DataFrame(index=range(500),columns=user_id_clstr1[:to_plot]) \n",
    "df_innov_rate_2 = pd.DataFrame(index=range(500),columns=user_id_clstr2[:to_plot]) \n",
    "df_innov_rate_3 = pd.DataFrame(index=range(500),columns=user_id_clstr3[:to_plot]) \n",
    "\n",
    "\n",
    "treatment_ = 'Pricing' #Pricing, Nudging, Control\n",
    "\n",
    "\n",
    "#Init df to have the mean innovation rates in a single df\n",
    "mean_innov_rate = pd.DataFrame(index=range(500),columns=['exclusive_phase1', 'moderate_phase1', 'mixed_phase1','exclusive_phase2', 'moderate_phase2', 'mixed_phase2'])\n",
    "\n",
    "for phase_ in [1,2]:\n",
    "    #Exclusive car users, user_id_clstr1\n",
    "    for user_id_ in user_id_clstr1[:to_plot]:\n",
    "        try:\n",
    "            y = get_inno_rate_per_phase(mtf_treatment, user_id_, phase=phase_, treatment=treatment_)\n",
    "            x = np.arange(0, len(y), 1).tolist()\n",
    "            df_innov_rate_1.loc[x, user_id_] = y\n",
    "        except:\n",
    "            continue        \n",
    "    \n",
    "    mean_innov_rate.loc[:, 'exclusive_phase%d' %phase_] = df_innov_rate_1.mean(axis=1)\n",
    "    \n",
    "    #Moderate car users, user_id_clstr2\n",
    "    for user_id_ in user_id_clstr2[:to_plot]:\n",
    "        try:\n",
    "            y = get_inno_rate_per_phase(mtf_treatment, user_id_, phase=phase_, treatment=treatment_)\n",
    "            x = np.arange(0, len(y), 1).tolist()\n",
    "            df_innov_rate_2.loc[x, user_id_] = y\n",
    "        except:\n",
    "            continue        \n",
    "    \n",
    "    mean_innov_rate.loc[:, 'moderate_phase%d' %phase_] = df_innov_rate_2.mean(axis=1)\n",
    "\n",
    "    #Mixed car users, user_id_clstr3\n",
    "    for user_id_ in user_id_clstr3[:to_plot]:\n",
    "        try:\n",
    "            y = get_inno_rate_per_phase(mtf_treatment, user_id_, phase=phase_, treatment=treatment_)\n",
    "            x = np.arange(0, len(y), 1).tolist()\n",
    "            df_innov_rate_3.loc[x, user_id_] = y\n",
    "        except:\n",
    "            continue        \n",
    "    \n",
    "    mean_innov_rate.loc[:, 'mixed_phase%d' %phase_] = df_innov_rate_3.mean(axis=1)\n",
    "\n",
    "mean_innov_rate.head(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f593f-80b1-4fae-9410-3db7e8082ff4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T15:30:35.971970Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_innov_rate_cluster1 = sns.lineplot(data=mean_innov_rate[['exclusive_rate_phase1','moderate_rate_phase1', 'mixed_rate_phase1']][:25]) #, legend=False\n",
    "#plot_innov_rate_cluster1.get_figure().savefig(\"innov_rate_modal_clus__phase1%s.png\"%treatment_, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
