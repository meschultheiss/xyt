{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance: GPStoGraph()\n",
    "Takes as input the output of `GPSAnalytics().metrics.get_metrics()`\n",
    "\n",
    "The public methods should be the following:\n",
    "- `get_graphs()`\n",
    "- `plot_motif()`\n",
    "- `plot_graph()`\n",
    "- `motif_sequence()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import gif\n",
    "from matplotlib.collections import LineCollection\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "\n",
    "\n",
    "from itertools import groupby\n",
    "import multiprocessing as mp\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "#nrows = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GPStoGraph().get_graphs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_use = ['user_id','user_id_day','location_id','started_at','finished_at', 'lon', 'lat', 'home_location_id']\n",
    "# Here we input df from part 1\n",
    "nodes = pd.read_pickle('sample_data/extended_staypoint_sample_panel.pkl')[col_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.sort_values(by=['user_id_day', 'started_at'])\n",
    "nodes = nodes.drop_duplicates(subset=['user_id_day', 'location_id', 'started_at'])\n",
    "nodes.reset_index(inplace=True, drop=True)\n",
    "\n",
    "mtfs = pd.DataFrame(index = nodes.user_id_day.unique())\n",
    "mtfs['mtf_loc'] = np.nan\n",
    "mtfs['mtf_loc'] =  mtfs['mtf_loc'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nodes(nodes):\n",
    "    \"\"\"\n",
    "    Preprocess GPS data by removing consecutive duplicate location entries.\n",
    "\n",
    "    Args:\n",
    "    - nodes (pd.DataFrame): DataFrame containing GPS data.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Preprocessed GPS data.\n",
    "    \"\"\"\n",
    "    # Create a copy of the original DataFrame\n",
    "    nodes_ = nodes.reset_index(drop=True).copy()\n",
    "\n",
    "    # Shift the location_id to create a 'location_id_next' column\n",
    "    nodes_['location_id_next'] = nodes_.groupby('user_id_day')['location_id'].shift(-1)\n",
    "\n",
    "    # Identify consecutive duplicate locations and remove them\n",
    "    index_to_drop = []\n",
    "    i = 0\n",
    "    for i_0 in nodes_.loc[nodes_.location_id == nodes_.groupby('user_id_day')['location_id'].shift(-1)].index:\n",
    "        if i_0 <= i:\n",
    "            index_to_drop.append(i_0)\n",
    "            continue\n",
    "        else:\n",
    "            i = i_0\n",
    "            location_id = nodes_.loc[i, 'location_id']\n",
    "\n",
    "            while location_id == nodes_.loc[i, 'location_id_next']:\n",
    "                i += 1\n",
    "                index_to_drop.append(i)\n",
    "\n",
    "            # Update 'finished_at' and 'location_id_next' for the first occurrence\n",
    "            nodes_.loc[i_0, 'finished_at'] = nodes_.loc[i, 'finished_at']\n",
    "            nodes_.loc[i_0, 'location_id_next'] = nodes_.loc[i, 'location_id_next']\n",
    "\n",
    "    # Drop the identified duplicate locations and reset index\n",
    "    nodes_.drop(index_to_drop, inplace=True)\n",
    "    nodes_.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Create an 'edges' column with tuples of location_id and location_id_next\n",
    "    nodes_['edges'] = list(zip(nodes_.location_id, nodes_.location_id_next))\n",
    "\n",
    "    # Create a GeoDataFrame and parse geometry to a tuple of coordinates in the right projection\n",
    "    nodes_ = gpd.GeoDataFrame(nodes_, geometry=gpd.points_from_xy(nodes_.lon, nodes_.lat), crs=\"EPSG:4326\")\n",
    "    nodes_['coordinates'] = list(zip(nodes_.geometry.x, nodes_.geometry.y))\n",
    "\n",
    "    return nodes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ = preprocess_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motifs(nodes):\n",
    "    \n",
    "    mtfs = pd.DataFrame(index = nodes.user_id_day.unique())\n",
    "    mtfs['graph'] = np.nan\n",
    "    mtfs['graph_flat'] = np.nan\n",
    "\n",
    "    mtfs['graph'] =  mtfs['graph'].astype('object')\n",
    "    mtfs['graph_flat'] =  mtfs['graph_flat'].astype('object')\n",
    "\n",
    "\n",
    "    for user_id_ in mtfs.index:\n",
    "       \n",
    "        nodes_ = nodes.loc[nodes.user_id_day == user_id_]\n",
    "            \n",
    "        try:\n",
    "            \n",
    "            attributes = nodes_.drop_duplicates(subset= ['user_id_day','location_id', 'started_at', 'finished_at'])[['user_id_day','location_id','coordinates', 'started_at', 'finished_at']]\n",
    "            attributes.set_index('location_id', inplace=True)\n",
    "            \n",
    "            attributes_time = attributes.groupby(by=['location_id']).aggregate({'started_at': list, 'finished_at': list})\n",
    "            attributes_time = attributes_time.groupby(level=0).apply(lambda attributes_time: attributes_time.xs(attributes_time.name).to_dict()).to_dict()\n",
    "            \n",
    "            attributes_location = pd.DataFrame(attributes['coordinates'].drop_duplicates()).T.to_dict()\n",
    "        \n",
    "            G = nx.DiGraph()\n",
    "            G.add_edges_from(nodes_.edges[:-1].to_list())\n",
    "        \n",
    "            nx.set_node_attributes(G, attributes_time, name='time')\n",
    "            nx.set_node_attributes(G, attributes_location)\n",
    "            \n",
    "            mtfs.at[user_id_, 'graph'] = G\n",
    "            mtfs.at[user_id_, 'graph_flat'] = nx.to_numpy_array(G).flatten().tolist()\n",
    "\n",
    "            \n",
    "        except:\n",
    "            print('Exception raised for ' + str(user_id_))\n",
    "            continue\n",
    "            \n",
    "    return mtfs.reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cores = mp.cpu_count() - 1\n",
    "print('Multiprocessing is launched with %s cores in parallel'%cores)\n",
    "print('...')\n",
    "\n",
    "#split the df in as many array as the machine has cores\n",
    "user_ids = np.array_split(nodes_.user_id_day.unique(), cores, axis=0)\n",
    "nodes_split = []\n",
    "for u in user_ids:\n",
    "    nodes_split.append(nodes_.loc[nodes_.user_id_day.isin(u.tolist())])\n",
    "    \n",
    "# create the multiprocessing pool\n",
    "pool = Pool(cores)\n",
    "\n",
    "# process the DataFrame by mapping function to each df across the pool\n",
    "df_out = np.vstack(pool.map(get_motifs, nodes_split))\n",
    "\n",
    "\n",
    "# return the df\n",
    "mtf = pd.DataFrame(df_out, columns=['user_id_day', 'DiGraph_motif', 'motif_flat'])\n",
    "\n",
    "# close down the pool and join\n",
    "pool.close()\n",
    "pool.join()\n",
    "pool.clear()\n",
    "\n",
    "\n",
    "mtf.set_index('user_id_day', inplace=True)\n",
    "mtf['user_id'] = mtf.index.str[:5]\n",
    "    \n",
    "#mtf.to_pickle('../data/repeateable_behavior/mtf_all.pkl')\n",
    "\n",
    "print('Job done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GPStoGraph().plot_graph()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gif.frame\n",
    "def plot_graph(user_id_, i):\n",
    "\n",
    "    G_all = nx.compose_all(mtf.loc[mtf.user_id == user_id_, 'DiGraph_motif'].values.tolist())\n",
    "    \n",
    "    user_id_day_ = mtf.loc[mtf.user_id == user_id_].index[i]\n",
    "    \n",
    "    G1 = mtf.loc[user_id_day_, 'DiGraph_motif']\n",
    "    \n",
    "    f = plt.figure(frameon=False,figsize=(10,10),dpi=100) #figsize=(10,10),dpi=50,\n",
    "    \n",
    "    #plot the backgroud graph\n",
    "    pos = nx.get_node_attributes(G_all, 'coordinates')\n",
    "    nx.draw_networkx_edges(G_all, pos, edge_color='black', alpha=0.20, arrowstyle=\"->\", arrowsize=15, width=1,connectionstyle='arc3,rad=+0.15') #wedge,shrink_factor=0.5\n",
    "    nx.draw_networkx_nodes(G_all, pos, node_color='black', alpha=0.20,node_size=70, nodelist = list(G_all.nodes())[1:])\n",
    "    nx.draw_networkx_nodes(G_all, pos, node_color='#dbcc9c', alpha=0.90,node_size=100, nodelist=list(G_all.nodes())[:1])\n",
    "\n",
    "    #plot the new daily graph\n",
    "    pos = nx.get_node_attributes(G1, 'coordinates')\n",
    "    nx.draw_networkx_edges(G1, pos, edge_color='black', alpha=0.90, arrowstyle=\"->\", arrowsize=15, width=2,connectionstyle='arc3,rad=+0.15') #wedge,shrink_factor=0.5\n",
    "    nx.draw_networkx_nodes(G1, pos, node_color='black', alpha=0.90,node_size=100, nodelist = list(G1.nodes())[1:])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for user_id_ in random.choices(mtf.user_id.unique(), k=2):\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, len(mtf.loc[mtf.user_id == user_id_].index)):\n",
    "        frames.append(plot_graph(user_id_, i))\n",
    "        \n",
    "    gif.save(frames, path=\"%s.gif\"%user_id_, \n",
    "             duration=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GPStoGraph().plot_motif()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse motif_id\n",
    "mtf_ = mtf.copy()\n",
    "motif_to_keep = 9\n",
    "mtf_['motif_id'] = 99\n",
    "\n",
    "for i_, mtf in enumerate(mtf_.motif_flat.value_counts().index[:motif_to_keep]):   \n",
    "    mtf_.loc[mtf_.motif_flat.apply(lambda x: x == mtf), 'motif_id'] = i_+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf_list = mtf_.groupby('motif_id')['motif_flat'].agg(\n",
    "                    motif_flat=pd.Series.mode,\n",
    "                    count=pd.Series.count)\n",
    "mtf_list['count'] = mtf_list['count'] / mtf_list['count'].sum()\n",
    "mtf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(frameon=False,figsize=(20,2),) #figsize=(10,10),dpi=50, \n",
    "\n",
    "for sublot, id_ in enumerate(mtf_list.index[:-1]):\n",
    "    \n",
    "    axis = f.add_subplot(1,9,sublot+1, xticks=[], yticks=[],frame_on=False, title='MOTIF %s\\n(%s%%)'%(id_,round(mtf_list.loc[id_, 'count']*100,1))) #title='motif %s (%d%%)'%(counter,expl_)  \n",
    "    motif = mtf_list.loc[id_, 'motif_flat']\n",
    "    dim = np.sqrt(len(motif)).astype(int)\n",
    "    motif_arr = np.asarray(motif).reshape((dim, dim)) \n",
    "    G = nx.DiGraph(motif_arr)\n",
    "    pos = nx.circular_layout(G)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='black', alpha=0.80, arrowstyle=\"->\", arrowsize=15, width=1,connectionstyle='arc3,rad=+0.15') #wedge,shrink_factor=0.5\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='black',node_size=70, nodelist = list(range(1,dim)))\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='#dbcc9c',node_size=80, nodelist=[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `GPStoGraph().motif_sequence()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf_ = mtf_.reset_index()\n",
    "mtf_['date'] = mtf_['user_id_day'].str[-8:]\n",
    "mtf_['date'] = pd.to_datetime(mtf_['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_mtf_sequence(mtf_data, user_id, pad=31):\n",
    "    \"\"\"\n",
    "    Get a motif sequence for a specific user.\n",
    "\n",
    "    Args:\n",
    "    - treatment (pd.DataFrame): DataFrame containing treatment information.\n",
    "    - mtf_data (pd.DataFrame): DataFrame containing motif data.\n",
    "    - user_id (str): User identifier.\n",
    "    - pad (int): Length of the output sequence (default is 31).\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Padded motif sequence for the specified user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract motif data for the specified user\n",
    "    sequence = mtf_data.loc[mtf_data['user_id'] == user_id, ['motif_id', 'date']].set_index('date').sort_index()\n",
    "    \n",
    "    # Align the first observation on Monday\n",
    "    pad_before = 0\n",
    "    if len(sequence) > 0:\n",
    "        pad_before = sequence.index.dayofweek[0]  # 0 is Monday, 1 is Tuesday, etc.\n",
    "\n",
    "    # Resample the time series to have continuous days, fill in missing values with 0\n",
    "    sequence = sequence.resample('1D').mean().fillna(0).astype(int).reset_index(drop=True).T\n",
    "    \n",
    "    # Make all the series the same length by padding after\n",
    "    pad_after_ = pad - sequence.shape[1] - pad_before\n",
    "    pad_after = max(0, pad_after_)\n",
    "\n",
    "    if sequence.shape[1] > pad:\n",
    "        return np.pad(sequence.values.flatten(), pad_width=[pad_before, 0], mode='constant')[:pad]\n",
    "    else:\n",
    "        return np.pad(sequence.values.flatten(), pad_width=[pad_before, pad_after], mode='constant')[:pad]\n",
    "\n",
    "# Example usage:\n",
    "# motif_sequence = get_mtf_sequence(treatment_data, mtf_data, phase=1, user_id='your_user_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 60\n",
    "\n",
    "mtf_seq = pd.DataFrame(index = mtf_.user_id.unique(), columns = range(n_cols))\n",
    "\n",
    "for usrs in mtf_.user_id.unique():\n",
    "    try:\n",
    "        mtf_seq.loc[usrs] = get_mtf_sequence(mtf_, user_id = usrs, pad= n_cols).tolist()\n",
    "    except:\n",
    "        print('Exception raised on user ' + usrs + ' / phase 1')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
